{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mailparser\n",
    "import re\n",
    "import pandas as pd\n",
    "import io\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EmlFileParser(object):\n",
    "    def __init__(self, file):\n",
    "        super().__init__()\n",
    "        self.file = file   \n",
    "\n",
    "    def parse_metropolitaine(self):\n",
    "        df = self.parse()\n",
    "        df = df.filter(regex='SITREP|^J\\s|^L\\s|^N\\s')\n",
    "        df.iloc[:,0] =df.columns[0]\n",
    "        df = df.rename(columns={df.columns[0]: \"cross_sitrep\"})\n",
    "        df['cross_sitrep'] = df.cross_sitrep.str.replace('=C9', \"E\").str.extract(\"(?:MRCC|CROSS|JRCC) ((?:LA*\\s)*[A-Z]+\\/\\d+/(?:N°)*\\d+)\")\n",
    "        df = self.colname_homogeneous(df)\n",
    "        return df\n",
    "  \n",
    "    def parse_tahiti(self):\n",
    "        df = self.parse()\n",
    "        df = df.filter(regex='BT|JRCC|^J-|^L-|^N-')\n",
    "        df.iloc[:,0] =df.columns[0]\n",
    "        df = df.rename(columns={df.columns[0]: \"cross_sitrep\"})\n",
    "        df['cross_sitrep'] = \"TAHITI/\"+df['BT'].str.extract('(\\d+/\\d+)')\n",
    "        df = df.drop(['BT', 'JRCC TAHITI'], axis=1)\n",
    "        df = self.colname_homogeneous(df)\n",
    "        return df\n",
    "    \n",
    "    def parse_reunion(self):\n",
    "        df = self.parse()\n",
    "        df = df.filter(regex='FM CROSS REUNION|^J-|^L-|^N-')\n",
    "        df.iloc[:,0] =df.columns[0]\n",
    "        df['cross_sitrep'] = df['FM CROSS REUNION'].str.extract('(?:CROSS) (R=C9UNION/\\d+/\\d+)').str.replace('=C9', 'E')\n",
    "        df = df.drop('FM CROSS REUNION', axis=1)\n",
    "        df = self.colname_homogeneous(df)\n",
    "        return df\n",
    "        \n",
    "    def colname_homogeneous(self, df):\n",
    "        di={'J - INITIAL ACTIONS TAKEN': 'J - PREMIERES MESURES PRISES',\n",
    "           'J - PREMIÈRES MESURES PRISES':'J - PREMIERES MESURES PRISES',\n",
    "           'J – PREMIERES MESURES PRISES':'J - PREMIERES MESURES PRISES',\n",
    "           'J-    PREMIERES MESURES PRISES':'J - PREMIERES MESURES PRISES',\n",
    "           'L - CHRONOLOGIE':'L - CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION',\n",
    "           'L - COORDINATING INSTRUCTIONS':'L - CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION',\n",
    "           'L-    INSTRUCTIONS POUR LA COORDINATION':'L - CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION',\n",
    "           'L – CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION':'L - CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION',\n",
    "           'N - ADDITIONAL INFORMATION':'N - RENSEIGNEMENTS COMPLEMENTAIRES',\n",
    "           'N - RENSEIGNEMENTS COMPLÉMENTAIRES':'N - RENSEIGNEMENTS COMPLEMENTAIRES',\n",
    "           'N - RENSEIGNEMENTS COMPLMENTAIRES':'N - RENSEIGNEMENTS COMPLEMENTAIRES',\n",
    "           'N – RENSEIGNEMENTS COMPLEMENTAIRES':'N - RENSEIGNEMENTS COMPLEMENTAIRES',\n",
    "           'N-    RENSEIGNEMENTS COMPLEMENTAIRES':'N - RENSEIGNEMENTS COMPLEMENTAIRES'}\n",
    "        return df.rename(columns=lambda x: x.strip()).rename(columns=di)\n",
    "      \n",
    "    def parse(self):\n",
    "        data = self.text_to_df()\n",
    "        data.columns =['lines'] #Name the dataframe column\n",
    "        data['A'], data['B'] = data['lines'].str.split('\\n',1).str #Split lines \n",
    "        data = data.drop_duplicates('A', keep='first') #Drop duplicated lines\n",
    "        data = data.transpose()# Transpose the Data frame \n",
    "        data.columns = data.iloc[1] #Name colums with info in row A\n",
    "        data = data.reindex(data.index.drop(['A','lines'])).reset_index() \n",
    "        return data\n",
    "    \n",
    "    def eml_to_text(self):\n",
    "        mail = mailparser.parse_from_file(self.file)\n",
    "        return mail.body\n",
    "\n",
    "    def text_to_df(self):\n",
    "        a =  self.eml_to_text().split('\\n\\n')\n",
    "        return pd.DataFrame(a)\n",
    "\n",
    "\n",
    "\n",
    "class EmlFolderParser(object):\n",
    "    def __init__(self, folder, output):\n",
    "        super().__init__()\n",
    "        self.folder = folder\n",
    "        self.output = output\n",
    "    \n",
    "    def parse_folder(self):\n",
    "        text_df = pd.DataFrame()\n",
    "        for filename in glob.glob(self.folder+'/*.eml'):\n",
    "            if ('TAHITI' in filename)== True:            \n",
    "                out = EmlFileParser(filename).parse_tahiti()\n",
    "            elif ('UNION' in filename)== True:\n",
    "                out = EmlFileParser(filename).parse_reunion()\n",
    "            else:\n",
    "                out = EmlFileParser(filename).parse_metropolitaine()\n",
    "            text_df = text_df.append(out, ignore_index=True)\n",
    "        text_df.to_csv(self.output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EmlFolderParser('./liste_sitrep', './liste_sitrep/test_all3.csv').parse_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_sitrep(input_path, output_path):\n",
    "    text_df = pd.DataFrame() \n",
    "    for filename in glob.glob(input_path+'/*.eml'):\n",
    "        mail = mailparser.parse_from_file(filename)\n",
    "        text = mail.body\n",
    "        a = text.split('\\n\\n')\n",
    "        df = pd.DataFrame(a)\n",
    "        df.columns =['test']\n",
    "        df['A'], df['B'] = df['test'].str.split('\\n',1).str \n",
    "        df = df.drop_duplicates('A', keep='first')\n",
    "        df1 = df.transpose()\n",
    "        df1.columns = df1.iloc[1]\n",
    "        df2 = df1.reindex(df1.index.drop('A')).reset_index()\n",
    "        df3 = df2.filter(regex='SITREP|^J\\s|^L\\s|^N\\s').drop(0)\n",
    "        df3.iloc[:,0] =df3.columns[0]\n",
    "        df3 = df3.rename(columns={ df3.columns[0]: \"cross_sitrep\"})\n",
    "        df3['cross_sitrep'] = df3.cross_sitrep.str.extract(\"(?:MRCC|CROSS|JRCC) ([A-Z]+\\/\\d+/(?:N°)*\\d+)\")#ajouter un truc pour La garde \n",
    "        text_df = text_df.append(df3, ignore_index=True)\n",
    "    text_df.to_csv(output_path)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elsa.luneville/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    }
   ],
   "source": [
    "parse_sitrep('./liste_sitrep', './liste_sitrep/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmlFileParserTest(object):\n",
    "    def __init__(self, file):\n",
    "        super().__init__()\n",
    "        self.file = file   \n",
    "\n",
    "    def parse_metropolitaine(self):\n",
    "        df = self.parse()\n",
    "        df = df.filter(regex='SITREP|^J\\s|^L\\s|^N\\s')\n",
    "        df.iloc[:,0] =df.columns[0]\n",
    "        df = df.rename(columns={df.columns[0]: \"cross_sitrep\"})\n",
    "        df['cross_sitrep'] = df.cross_sitrep.str.replace('=C9', \"E\").str.extract(\"(?:MRCC|CROSS|JRCC) ((?:LA*\\s)*[A-Z]+\\/\\d+/(?:N°)*\\d+)\")\n",
    "        df = self.colname_homogeneous(df)\n",
    "        return df\n",
    "  \n",
    "    def parse_tahiti(self):\n",
    "        df = self.parse()\n",
    "        df = df.filter(regex='|BT|JRCC|^J-|^L-|^N-')\n",
    "      #  df.iloc[:,0] =df.columns[0]\n",
    "       # df = df.rename(columns={df.columns[0]: \"cross_sitrep\"})\n",
    "       # df['cross_sitrep'] = \"TAHITI/\"+df['BT'].str.extract('(\\d+/\\d+)')\n",
    "       # df = df.drop(['BT', 'JRCC TAHITI'], axis=1)\n",
    "        #df = self.colname_homogeneous(df)\n",
    "        return df\n",
    "    \n",
    "    def parse_reunion(self):\n",
    "        df = self.parse()\n",
    "        df = df.filter(regex='FM CROSS REUNION|^J-|^L-|^N-')\n",
    "        df.iloc[:,0] =df.columns[0]\n",
    "        df['cross_sitrep'] = df['FM CROSS REUNION'].str.extract('(?:CROSS) (R=C9UNION/\\d+/\\d+)').str.replace('=C9', 'E')\n",
    "        df = df.drop('FM CROSS REUNION', axis=1)\n",
    "        df = self.colname_homogeneous(df)\n",
    "        return df\n",
    "        \n",
    "    def colname_homogeneous(self, df):\n",
    "        di={'J - INITIAL ACTIONS TAKEN': 'J - PREMIERES MESURES PRISES',\n",
    "           'J - PREMIÈRES MESURES PRISES':'J - PREMIERES MESURES PRISES',\n",
    "           'J – PREMIERES MESURES PRISES':'J - PREMIERES MESURES PRISES',\n",
    "           'J-    PREMIERES MESURES PRISES':'J - PREMIERES MESURES PRISES',\n",
    "           'L - CHRONOLOGIE':'L - CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION',\n",
    "           'L - COORDINATING INSTRUCTIONS':'L - CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION',\n",
    "           'L-    INSTRUCTIONS POUR LA COORDINATION':'L - CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION',\n",
    "           'L – CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION':'L - CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION',\n",
    "           'N - ADDITIONAL INFORMATION':'N - RENSEIGNEMENTS COMPLEMENTAIRES',\n",
    "           'N - RENSEIGNEMENTS COMPLÉMENTAIRES':'N - RENSEIGNEMENTS COMPLEMENTAIRES',\n",
    "           'N - RENSEIGNEMENTS COMPLMENTAIRES':'N - RENSEIGNEMENTS COMPLEMENTAIRES',\n",
    "           'N – RENSEIGNEMENTS COMPLEMENTAIRES':'N - RENSEIGNEMENTS COMPLEMENTAIRES',\n",
    "           'N-    RENSEIGNEMENTS COMPLEMENTAIRES':'N - RENSEIGNEMENTS COMPLEMENTAIRES'}\n",
    "        return df.rename(columns=lambda x: x.strip()).rename(columns=di)\n",
    "      \n",
    "    def parse(self):\n",
    "        data = self.text_to_df()\n",
    "        data.columns =['lines'] #Name the dataframe column\n",
    "        data['A'], data['B'] = data['lines'].str.split('\\n',1).str #Split lines \n",
    "        data = data.drop_duplicates('A', keep='first') #Drop duplicated lines\n",
    "        data = data.transpose()# Transpose the Data frame \n",
    "        data.columns = data.iloc[1] #Name colums with info in row A\n",
    "        data = data.reindex(data.index.drop(['A','lines'])).reset_index() \n",
    "        return data\n",
    "    \n",
    "    def eml_to_text(self):\n",
    "        mail = mailparser.parse_from_file(self.file)\n",
    "        return mail.body\n",
    "\n",
    "    def text_to_df(self):\n",
    "        a =  self.eml_to_text().split('\\n\\n')\n",
    "        return pd.DataFrame(a)\n",
    "\n",
    "\n",
    "\n",
    "class EmlFolderParser(object):\n",
    "    def __init__(self, folder, output):\n",
    "        super().__init__()\n",
    "        self.folder = folder\n",
    "        self.output = output\n",
    "    \n",
    "    def parse_folder(self):\n",
    "        text_df = pd.DataFrame()\n",
    "        for filename in glob.glob(self.folder+'/*.eml'):\n",
    "            if ('TAHITI' in filename)== True:            \n",
    "                out = EmlFileParser(filename).parse_tahiti()\n",
    "            elif ('UNION' in filename)== True:\n",
    "                out = EmlFileParser(filename).parse_reunion()\n",
    "            else:\n",
    "                out = EmlFileParser(filename).parse_metropolitaine()\n",
    "            text_df = text_df.append(out, ignore_index=True)\n",
    "        text_df.to_csv(self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>A</th>\n",
       "      <th>index</th>\n",
       "      <th>FM JRCC TAHITI</th>\n",
       "      <th></th>\n",
       "      <th>A-    NATURE DE L'EVENEMENT ET IDENTITE DU MOBILE IMPLIQUE</th>\n",
       "      <th>B-    POSITION</th>\n",
       "      <th>C-    SITUATION INITIALE</th>\n",
       "      <th>D-    NOMBRE DE PERSONNES IMPLIQUEES</th>\n",
       "      <th>E-    ASSISTANCE DEMANDEE</th>\n",
       "      <th>F-    CENTRE(S) DE COORDINATION</th>\n",
       "      <th>G-    DESCRIPTION DU MOBILE</th>\n",
       "      <th>J-    PREMIERES MESURES PRISES</th>\n",
       "      <th>K-    ZONES DE RECHERCHE</th>\n",
       "      <th>L-    INSTRUCTIONS POUR LA COORDINATION</th>\n",
       "      <th>M-    PLANS FUTURS</th>\n",
       "      <th>N-    RENSEIGNEMENTS COMPLEMENTAIRES</th>\n",
       "      <th>--</th>\n",
       "      <th>JRCC TAHITI</th>\n",
       "      <th>BP 9420 – 98715 Papeete CMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>TO HAUSSAIRE PF\\nDAM SM1\\nSG MER\\nCOFGC\\nCMVOA...</td>\n",
       "      <td>BT\\nNON PROTEGE\\nMCA SECMAR\\nOBJ/SITREP SAR 40...</td>\n",
       "      <td>CHAVIREMENT – PIROGUE TYPE V6</td>\n",
       "      <td>17°31S / 149°34W – PAPEETE - ILE DE TAHITI</td>\n",
       "      <td>LE 04/12/2017 A 17H00 – APPEL TELEPHONIQUE D’U...</td>\n",
       "      <td>6</td>\n",
       "      <td>RECHERCHE ET SAUVETAGE</td>\n",
       "      <td>JRCC TAHITI</td>\n",
       "      <td>PIROGUE DE COURSE TYPE V6\\nH-    CONDITI...</td>\n",
       "      <td>17H05 – DIFFUSION VHF 16 MESSAGE PAN-PAN...</td>\n",
       "      <td>NEANT</td>\n",
       "      <td>17H19 – 4 PERSONNES ONT ATTEINT LE RECIF...</td>\n",
       "      <td>NEANT</td>\n",
       "      <td>18H20 – OPERATION CLOSE\\n      1 PIROGUE...</td>\n",
       "      <td>[cid:part1.39C5180B.CE0C4293@mail.pf]</td>\n",
       "      <td>Centre de coordination de sauvetage aéro marit...</td>\n",
       "      <td>Tél : Urgence 24/24 : 16 – International : (+6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "A index                                     FM JRCC TAHITI  \\\n",
       "0     B  TO HAUSSAIRE PF\\nDAM SM1\\nSG MER\\nCOFGC\\nCMVOA...   \n",
       "\n",
       "A                                                     \\\n",
       "0  BT\\nNON PROTEGE\\nMCA SECMAR\\nOBJ/SITREP SAR 40...   \n",
       "\n",
       "A A-    NATURE DE L'EVENEMENT ET IDENTITE DU MOBILE IMPLIQUE  \\\n",
       "0                      CHAVIREMENT – PIROGUE TYPE V6           \n",
       "\n",
       "A                                    B-    POSITION  \\\n",
       "0        17°31S / 149°34W – PAPEETE - ILE DE TAHITI   \n",
       "\n",
       "A                           C-    SITUATION INITIALE  \\\n",
       "0  LE 04/12/2017 A 17H00 – APPEL TELEPHONIQUE D’U...   \n",
       "\n",
       "A D-    NOMBRE DE PERSONNES IMPLIQUEES     E-    ASSISTANCE DEMANDEE  \\\n",
       "0                                    6        RECHERCHE ET SAUVETAGE   \n",
       "\n",
       "A F-    CENTRE(S) DE COORDINATION  \\\n",
       "0                     JRCC TAHITI   \n",
       "\n",
       "A                        G-    DESCRIPTION DU MOBILE  \\\n",
       "0        PIROGUE DE COURSE TYPE V6\\nH-    CONDITI...   \n",
       "\n",
       "A                     J-    PREMIERES MESURES PRISES K-    ZONES DE RECHERCHE  \\\n",
       "0        17H05 – DIFFUSION VHF 16 MESSAGE PAN-PAN...                    NEANT   \n",
       "\n",
       "A            L-    INSTRUCTIONS POUR LA COORDINATION M-    PLANS FUTURS  \\\n",
       "0        17H19 – 4 PERSONNES ONT ATTEINT LE RECIF...              NEANT   \n",
       "\n",
       "A               N-    RENSEIGNEMENTS COMPLEMENTAIRES  \\\n",
       "0        18H20 – OPERATION CLOSE\\n      1 PIROGUE...   \n",
       "\n",
       "A                                     --  \\\n",
       "0  [cid:part1.39C5180B.CE0C4293@mail.pf]   \n",
       "\n",
       "A                                        JRCC TAHITI  \\\n",
       "0  Centre de coordination de sauvetage aéro marit...   \n",
       "\n",
       "A                        BP 9420 – 98715 Papeete CMP  \n",
       "0  Tél : Urgence 24/24 : 16 – International : (+6...  "
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmlFileParserTest('./liste_sitrep/JRCC TAHITI - SITREP SAR 406-2017- UN ET FINAL.eml').parse_tahiti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elsal\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>A</th>\n",
       "      <th>cross_sitrep</th>\n",
       "      <th>L - CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION</th>\n",
       "      <th>N - RENSEIGNEMENTS COMPLEMENTAIRES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LE 26/12/2017\\n03:25 – SUITE NOMBREUX APPELS P...</td>\n",
       "      <td>09:47 - OPÉRATION CLOSE\\n01 NAVIRE REMORQUÉ\\nBT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "A cross_sitrep    L - CHRONOLOGIE ET INSTRUCTIONS DE COORDINATION  \\\n",
       "0          NaN  LE 26/12/2017\\n03:25 – SUITE NOMBREUX APPELS P...   \n",
       "\n",
       "A               N - RENSEIGNEMENTS COMPLEMENTAIRES  \n",
       "0  09:47 - OPÉRATION CLOSE\\n01 NAVIRE REMORQUÉ\\nBT  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Handle cross reunion\n",
    "#Add message error\n",
    "#Split parsing function\n",
    "#make test"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
